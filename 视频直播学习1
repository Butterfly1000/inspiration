视频直播的关键在于视频和音频的实时性传输。
一般的视频和音频都会借助到安卓或ios，细节处理上确实需要很多学习。

在网上的学习后发现有一种视频直播是基本php+swoole+h5(canvas,video),这种实现方式，经过测试，利用navigator.getUserMedia我们可以调用
移动端（手机）的摄像头（必须经过同意），然后通过将数据播放在H5的video标签，之后使用canvas的drawImage，将video的视频内容生成一张张图片，
然后通过toDataURL将图片转成url格式数据，之后通过swoole实现实时传输，在客服端，就可以看到图像。
但后期会发现，即使我们根本还未考虑音频及后期的并发问题，就是简单的图片实时录制，传输，展示也会出现问题，问题出现在drawImage的绘制速度完全
跟不上，这就会导致图像极其延迟。

因此，接着分析视频直播的一些原理，
https://blog.csdn.net/weixin_39371129/article/details/74516386 【转】
★.采取，封装，解码
一、封装格式
1、因为来源的不同，视频会有不同的格式，分别用不同的后缀表示，avi/rmvb/mp4等，这些格式代表的就是封装格式
2、封装格式就是把已经压缩编码视频数据和音频数据按照一定的格式放到一起，不同的封装格式之间差距不大，各有优劣
3、封装格式支持音视频编码标准，有些封装格式支持的音视频编码标准十分广泛，比如MKV，而有些封装格式支持的视音频编码标准很少，属于落后的封装格式，
比如RMVB，所以单从封装格式无法看出某视频具体使用了什么音视频编码标准。

二、视频播放器播放一个互联网上的视频文件，需要经过以下几个步骤:

1、解协议
   1）就是将流媒体协议的数据，解析为标准的相应的封装格式的数据。
   2）音视频在网络上传播的时候，常常采用各种流媒体协议,例如HTTP/RTMP/MMS等等，这些协议在传输数据的同时，也会传输一些信令数据，
   这些信令数据包括对播放的控制（播放，暂停，停止），或者对网络状态的描述等。
   3）解协议的过程中会去掉信令数据而只保留音频数据，例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。
 
2、解封装的作用
   将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据，例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流
 
3、解码
    解码是整个系统中最重要也是最复杂的一个环节，通过解码，
       压缩编码的视频数据输出成非压缩的颜色数据，例如YUV420P，RGB等等，
       压缩编码的音频数据输出称为非压缩的音频抽样数据，例如PCM数据
 
4、音视频同步
     根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将音频视频数据送至系统的显卡和声卡播放出来
当然，以上内容基本都是借助封装好的工具。

★.直播相关知识
一、在客户端上要完成直播视频的采集及RTMP上推，主要需要以下几个步骤：
1、音视频的采集
   在音频的采集上，直接使用DirectShow获取原始格式的音视频数据。
   
2、对视频进行H264编码，对音频进行AAC编码
  使用FFmpeg进行编码
  
3、对编码后的音视频进行FLV封包

4、建立RTMP连接并推到SRS流媒体服务器上

二、在传输直播流媒体过程中的内容缓存与传输策略优化细节原理
1、基础知识：I帧、P帧、B帧
  1）I帧表示关键帧
     包含完整画面，解码时只需要本帧数据就可以完成
 
  2）P帧表示这一帧跟之前的一个关键帧的差别
     解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面，因此也叫作差别帧
 
  3）B帧是双向差别帧
     B帧记录的是本帧与前后帧的差别，换言之，要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面与本帧数据的叠加取得最终的画面
     B帧压缩率高，但是编解码时会比较耗费CPU,而且在直播中可能会增加直播延时，因此在移动端上一般不适用B帧
 
2、关键帧缓存策略
  1）一个典型的视频帧序列为IBBPBBPBBP....
  
  2) 对于直播而言，为了减少直播的延时，通常在编码时不使用B帧，P帧B帧对于I帧都有直接或者间接的依赖关系，所以播放器要解码一个视频帧序列，
  必须首先解码出I帧，其后续的B帧和P帧才能进行解码
  
  3）服务端如何进行关键帧的缓存，对直播的延时有非常大的影响，比较好的策略是服务器端自动判断关键帧的间隔，按业务需求缓存帧序列，
  保证在缓存中存储至少两个或以上的关键帧，以应对低延时、放卡顿、只能丢包等问题
 
3、延迟与卡顿的折中
   1、直播的延时与卡顿是分析直播业务质量的两个重要指标，互动直播的场景对延迟非常敏感，新闻类体育类直播则更加关注播放的流畅度
 
   2、延时与卡顿从理论上来说，是一对矛盾的关系
     - 需要更低的延时，则表明服务器端和播放段的缓存区都必须更短，来自网络的异常抖动容易引起卡顿
     - 需要更流畅的直播体验，则表明服务端和播放段都可以有较长的缓冲区，以应对网络的抖动，提供更流畅的直播体验
 
   3、对于网络条件非常好的用户，这两项是可以同时保证的，这里主要针对网络条件不是那么好的用户，如何解决延时与卡顿的问题
 
 4、两种技术来平衡和优化这两个指标
   1）服务端提供灵活的配置策略，服务端对所有连接的网络情况进行智能检测，
       当网络状况良好时，在服务端保证关键帧的情况下，服务端会缩小该链接的缓冲队列的大小，降低延迟
       当网络环境差时，特别是检测到抖动较为明显时，服务端对该链接增加缓冲队列长度，优先保证播放的流畅性

   2）丢包策略
      对于一个网络链接很好，延时也比较小的连接，丢包策略永远没有用武之地.
      一般的丢帧策略，就是直接丢弃一个完整的视频帧序列，这种策略看似简单，但对用户播放的影响体验非常大。而应该是后台采用逐步丢帧的策略，
      每个视频帧序列，丢最后的一到两帧，使得用户的感知最小，平滑的逐步缩小延时的效果。
  
★.RTMP协议
基本概念
1、RTMP协议是Adobe公司为Flash播放器和服务器之间音、视频及数据传输开发的实时消息传送协议。协议中，视频必须是H264编码，音频必须是AAC或MP3编码，
且多以flv格式封包。

RTMP传输数据原理
 1）发送端首先把媒体数据封装成消息，然后把消息分割成消息块，最后将分割后的消息块，通过TCP协议发送出去
 
 2）接收端在通过TCP协议收到数据后，首先把消息块重新组合成消息，然后通过将消息解封装就可以恢复出媒体数据

RTMP协议中的相关概念
RTMP协议是TCP/IP五层体系结构中应用层的协议，RTMP协议中基本的数据单元称为消息，当使用RTMP协议传输消息时，消息会被拆分成更小的单元，称为消息块
1、消息
 1）是RTMP协议中基本的数据单元
 
 2）消息分为两大部分
    消息首部(Message Header)
      标志消息类型的Message Type ID
      标志消息长度的Payload Length
      标识时间戳的Timestamp
      标识消息所属媒体流的Stream ID
 
    消息负载(Message Body)
       传输的信息
 
 3）不同种类的消息包含不同的Message Type ID，RTMP协议中一共规定了十多种消息类型，分别发挥着不同的作用
   1-7
     用于协议控制，这些消息一般是RTMP协议自身管理要使用的消息，用户一般情况下无需操作其中的数据
   8-9
     分别用于传输音频视频数据
   15-20
     用于发送AMF编码的命令，负责用户与服务器之间的交互，比如播放，暂停等等

2、消息块
  1、在网络上传输数据时，消息需要拆分成较小的数据块，才适合在相应的网络环境上传输
 
  2、在消息被分割成几个消息块的过程中，消息负载部分（Message Body）被分割成大小固定的数据块（默认是128字节，最后一个数据块可以小于该固定长度），
  并在其首部加上消息块首部（Chunk Header），就组成了相应的消息块。

RTMP流媒体播放过程
RTMP协议规定，播放一个流媒体有两个前提步骤，
1、第一步，建立一个网络连接
  服务端应用程序和客户端之间基础的连通关系
2、第二步，建立一个网络流
  网络流代表了发送多媒体数据的通道，服务端和客户端之间只能建立一个网络连接，但是基于该连接可以创建很多网络流。
  
